{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shap\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense,Activation,Dropout, Flatten, Concatenate, concatenate, Input, Lambda\n",
    "# from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import batch_normalization \n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "## Util Functions\n",
    "# def convert_to_int()\n",
    "\n",
    "def get_reshape(row):\n",
    "    # print(row)\n",
    "    return np.fromstring(row['grid'].replace('\\n','')\n",
    "                                    .replace('[','')\n",
    "                                    .replace(']','')\n",
    "                                    .replace('  ',' '), sep=' ').reshape(row['grid_rows'],row['grid_columns'])\n",
    "\n",
    "def convert_obs(df):\n",
    "    return df['observation'].apply(lambda x: \n",
    "                           np.fromstring(\n",
    "                               x.replace('\\n','')\n",
    "                                .replace('[','')\n",
    "                                .replace(']','')\n",
    "                                .replace('  ',' '), sep=' '))\n",
    "\n",
    "def gen_heatmap(df,f, ax):\n",
    "    df = df.reset_index()\n",
    "    x_array = df['x'].to_numpy()\n",
    "    y_array =df['y'].to_numpy()\n",
    "    grid = np.zeros((df['grid_rows'][0],df['grid_columns'][0]))\n",
    "    for i, j in zip(y_array,x_array):\n",
    "        grid[i,j]+=1\n",
    "    heat =sns.heatmap(grid,cmap='viridis',alpha =0.6,zorder=2,ax=ax)\n",
    "    my_image = mpimg.imread(f)\n",
    "    # plt.imshow(my_image)\n",
    "    plt.title(df['experiment'][0])\n",
    "    ax.heat.imshow(my_image,aspect=heat.get_aspect(),extent= heat.get_xlim() + heat.get_ylim(),zorder=1)\n",
    "    # plt.close()\n",
    "    # return heat\n",
    "\n",
    "def keras_classifier(n_inputs,n_outputs):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1000, input_dim= n_inputs, activation='relu'))\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "## Data Handling\n",
    "### Reading in the data \n",
    "df1 = pd.read_csv('./data/data.csv')\n",
    "df = pd.read_csv('./data/data_policy_switching.csv')\n",
    "df.describe()\n",
    "### Data Manipulation\n",
    "\n",
    "# Modify the grid to be a correct numpy array representing the level\n",
    "df1['grid'] = df1[['grid','grid_rows','grid_columns']].apply(lambda x: get_reshape(x),axis=1)\n",
    "df['grid'] = df[['grid','grid_rows','grid_columns']].apply(lambda x: get_reshape(x),axis=1)\n",
    "\n",
    "# format the observation space into numpy array\n",
    "df1['observation'] = convert_obs(df1)\n",
    "df['observation'] = convert_obs(df)\n",
    "\n",
    "# Shuffle the data \n",
    "df1 = df1.sample(frac=1)\n",
    "df = df.sample(frac=1)\n",
    "df.head()\n",
    "# split the observation into seperate columns\n",
    "# observations = [dist_monster, dist_treaure, safe_dist_teasure, dist_potion, safe_dist_potion, dist_exit, safe_dist_exit, HP]\n",
    "obs = ['dist_monster', 'dist_treaure', 'safe_dist_teasure', 'dist_potion', 'safe_dist_potion', 'dist_exit', 'safe_dist_exit', 'HP']\n",
    "\n",
    "df1[obs] = pd.DataFrame(df1['observation'].to_list(), index= df1.index)\n",
    "df[obs] = pd.DataFrame(df['observation'].to_list(), index= df.index)\n",
    "df1.describe()\n",
    "\n",
    "## Creating the dataset\n",
    "data = df[['dist_monster', 'dist_treaure', 'safe_dist_teasure', 'dist_potion', 'safe_dist_potion', 'dist_exit', 'safe_dist_exit', 'HP', 'action']]\n",
    "data\n",
    "# data[obs] = (df[obs]-df[obs].mean())/df[obs].std()\n",
    "y_data = pd.get_dummies(df['action'])\n",
    "print(y_data)\n",
    "sns.pairplot(data=data, hue = 'action')\n",
    "x_data = data[obs].to_numpy()\n",
    "y_data = data['action']\n",
    "print(y_data)\n",
    "### Split data\n",
    "x_train, x_test,y_train, y_test = train_test_split(x_data,y_data,test_size=.2, random_state=42)\n",
    "### create and train model (sklearn logistic regression)\n",
    "model_LG = sklearn.linear_model.LogisticRegression(max_iter=100000000, tol=1e-12)\n",
    "model_LG.fit(x_train,y_train)\n",
    "model_LG.score(x_test,y_test)\n",
    "# nn = MLPClassifier(solver=\"adam\",alpha=1e-0001,hidden_layer_sizes=(8,8,8),random_state=42, max_iter=10000000000000)\n",
    "# nn.fit(data[obs].values,data['action'].values)\n",
    "# nn.score(x_test,y_test)\n",
    "\n",
    "nn = MLPClassifier(solver=\"adam\",alpha=1e-0001,hidden_layer_sizes=(20,20,20),random_state=42, max_iter=10000000000000)\n",
    "nn.fit(df[obs].values,df['action'].values)\n",
    "nn.score(df[obs].values,df['action'].values)\n",
    "nn1 = MLPRegressor(alpha=1e-1, hidden_layer_sizes=(8,8,8), random_state=0, max_iter=1000000000)\n",
    "# nn1.fit(df[obs],y_train)\n",
    "explainerKernel = shap.KernelExplainer(nn.predict_proba,data[obs])\n",
    "shap_vals = explainerKernel.shap_values(x_test)\n",
    "# shap.force_plot(explainer.expected_value[0],shap_vals[0],x_test)\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "# shap.force_plot(explainer.expected_value[0],shap_vals[0],x_test)\n",
    "shap.summary_plot(shap_vals,feature_names=data[obs].columns, class_names= y_data.columns)\n",
    "# Create the list of all labels for the drop down list\n",
    "list_of_labels = y_data.columns.to_list()\n",
    "\n",
    "# Create a list of tuples so that the index of the label is what is returned\n",
    "tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))\n",
    "\n",
    "# Create a widget for the labels and then display the widget\n",
    "current_label = widgets.Dropdown(options=tuple_of_labels,\n",
    "                              value=0,\n",
    "                              description='Select Label:'\n",
    "                              )\n",
    "\n",
    "# Display the dropdown list (Note: access index value with 'current_label.value')\n",
    "current_label\n",
    "\n",
    "shap.summary_plot(shap_values = shap_vals[current_label.value],feature_names= data[obs].columns)\n",
    "# plot for all 4 classes\n",
    "shap.bar_plot(shap_values = shap_vals[current_label.value])\n",
    "explainer = shap.Explainer(nn.predict_proba, data[obs])\n",
    "shap_values = explainer(data[obs])\n",
    "shap.summary_plot(shap_values[current_label.value])\n",
    "\n",
    "\n",
    "## Keras and big dataset\n",
    "ldata =['dist_monster', 'dist_treaure', 'safe_dist_teasure', 'dist_potion', 'safe_dist_potion', 'dist_exit', 'safe_dist_exit', 'HP', 'action']\n",
    "data = pd.concat([df[ldata],df1[ldata]], ignore_index=True)\n",
    "data\n",
    "x_data = data[obs]\n",
    "y_data = pd.get_dummies(data['action'])\n",
    "y_data.head()\n",
    "\n",
    "nn = MLPClassifier(solver=\"adam\",alpha=1e-0001,hidden_layer_sizes=(20,20,20),random_state=42, max_iter=10000000000000)\n",
    "nn.fit(data[obs].values,data['action'].values)\n",
    "nn.score(data[obs].values,data['action'].values)\n",
    "model = keras_classifier(len(x_data.columns), len(y_data.columns))\n",
    "model.summary()\n",
    "model.fit(x_data.values,y_data.values,batch_size=20, epochs= 50, verbose=1)\n",
    "def f(X):\n",
    "    return model.predict([X[:,i] for i in range(X.shape[1])])\n",
    "Kernel_explainer = shap.KernelExplainer(model.predict, x_data.iloc[:50,:])\n",
    "# deep_explainer = shap.DeepExplainer(model,x_data.iloc[:50,:])\n",
    "exact_explainer = shap.explainers.Exact(model.predict, x_data.iloc[:50,:])\n",
    "kernel_shap_values = Kernel_explainer.shap_values(X = x_data.iloc[:50,:],nsamples=100)\n",
    "shap.summary_plot(kernel_shap_values, features=x_data.iloc[:50,:])\n",
    "kernel_shap_values\n",
    "fig, axs = plt.subplots(2,3)\n",
    "shap.summary_plot(kernel_shap_values, features=x_data.iloc[:50,:],)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
